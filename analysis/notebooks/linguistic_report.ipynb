{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文语料分析报告 📊\n",
    "\n",
    "本笔记本用于分析个人微信公众号语料的词频、关键词和可视化趋势。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置图表样式\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "# 添加源代码路径\n",
    "sys.path.append('../src')\n",
    "\n",
    "print(\"📚 环境设置完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取分析结果\n",
    "output_dir = '../out'\n",
    "\n",
    "# 检查文件是否存在\n",
    "files_to_check = [\n",
    "    'freq_overall.csv',\n",
    "    'freq_by_year.csv', \n",
    "    'tfidf_topk_by_year.csv'\n",
    "]\n",
    "\n",
    "existing_files = []\n",
    "for file in files_to_check:\n",
    "    file_path = os.path.join(output_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        existing_files.append(file)\n",
    "        print(f\"✅ 找到文件: {file}\")\n",
    "    else:\n",
    "        print(f\"❌ 文件不存在: {file}\")\n",
    "\n",
    "if not existing_files:\n",
    "    print(\"\\n⚠️ 请先运行 CLI 工具生成分析结果\")\n",
    "    print(\"运行命令: python -m analysis.src.cli --root Wechat-Backup/文不加点的张衔瑜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "freq_overall = pd.DataFrame()\n",
    "freq_by_year = pd.DataFrame()\n",
    "tfidf_by_year = pd.DataFrame()\n",
    "\n",
    "if 'freq_overall.csv' in existing_files:\n",
    "    freq_overall = pd.read_csv(os.path.join(output_dir, 'freq_overall.csv'))\n",
    "    print(f\"📊 整体词频数据: {len(freq_overall)} 个词汇\")\n",
    "\n",
    "if 'freq_by_year.csv' in existing_files:\n",
    "    freq_by_year = pd.read_csv(os.path.join(output_dir, 'freq_by_year.csv'))\n",
    "    years = sorted(freq_by_year['year'].unique()) if not freq_by_year.empty else []\n",
    "    print(f\"📅 年度词频数据: {len(years)} 年，{len(freq_by_year)} 条记录\")\n",
    "\n",
    "if 'tfidf_topk_by_year.csv' in existing_files:\n",
    "    tfidf_by_year = pd.read_csv(os.path.join(output_dir, 'tfidf_topk_by_year.csv'))\n",
    "    print(f\"🔍 TF-IDF 数据: {len(tfidf_by_year)} 条记录\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 整体词频分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not freq_overall.empty:\n",
    "    # Top 20 词汇条形图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_20 = freq_overall.head(20)\n",
    "    \n",
    "    bars = plt.barh(range(len(top_20)), top_20['freq'], \n",
    "                    color=plt.cm.viridis(np.linspace(0, 1, len(top_20))))\n",
    "    \n",
    "    plt.yticks(range(len(top_20)), top_20['word'])\n",
    "    plt.xlabel('词频')\n",
    "    plt.title('Top 20 高频词汇', fontsize=16, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # 添加数值标签\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        plt.text(width + width*0.01, bar.get_y() + bar.get_height()/2, \n",
    "                f'{int(width):,}', ha='left', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 统计摘要\n",
    "    total_words = len(freq_overall)\n",
    "    total_freq = freq_overall['freq'].sum()\n",
    "    top_10_freq = freq_overall.head(10)['freq'].sum()\n",
    "    \n",
    "    print(f\"\\n📈 整体统计摘要:\")\n",
    "    print(f\"总词汇数: {total_words:,}\")\n",
    "    print(f\"总词频: {total_freq:,}\")\n",
    "    print(f\"Top 10 词汇占比: {top_10_freq/total_freq:.1%}\")\n",
    "    print(f\"词汇多样性 (词汇数/总词频): {total_words/total_freq:.4f}\")\n",
    "else:\n",
    "    print(\"❌ 没有整体词频数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📅 年度趋势分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not freq_by_year.empty:\n",
    "    # 年度词汇量趋势\n",
    "    yearly_stats = freq_by_year.groupby('year').agg({\n",
    "        'word': 'nunique',  # 词汇数\n",
    "        'freq': 'sum'       # 总词频\n",
    "    }).rename(columns={'word': 'unique_words', 'freq': 'total_freq'})\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 年度词汇数变化\n",
    "    ax1.plot(yearly_stats.index, yearly_stats['unique_words'], \n",
    "             marker='o', linewidth=2, markersize=8, color='#2E86AB')\n",
    "    ax1.set_title('年度词汇数变化', fontweight='bold')\n",
    "    ax1.set_xlabel('年份')\n",
    "    ax1.set_ylabel('词汇数')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 年度总词频变化\n",
    "    ax2.plot(yearly_stats.index, yearly_stats['total_freq'], \n",
    "             marker='s', linewidth=2, markersize=8, color='#A23B72')\n",
    "    ax2.set_title('年度总词频变化', fontweight='bold')\n",
    "    ax2.set_xlabel('年份')\n",
    "    ax2.set_ylabel('总词频')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 显示数据表\n",
    "    yearly_stats['diversity'] = yearly_stats['unique_words'] / yearly_stats['total_freq']\n",
    "    print(\"\\n📊 年度统计:\")\n",
    "    print(yearly_stats.round(4))\n",
    "else:\n",
    "    print(\"❌ 没有年度词频数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not freq_by_year.empty:\n",
    "    # 选择几个有趣的词汇分析其年度变化\n",
    "    # 自动选择在多个年份都出现的高频词\n",
    "    word_year_counts = freq_by_year.groupby('word')['year'].nunique().sort_values(ascending=False)\n",
    "    multi_year_words = word_year_counts[word_year_counts >= 3].index[:8]  # 至少出现3年的前8个词\n",
    "    \n",
    "    if len(multi_year_words) > 0:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(multi_year_words)))\n",
    "        \n",
    "        for i, word in enumerate(multi_year_words):\n",
    "            word_data = freq_by_year[freq_by_year['word'] == word]\n",
    "            plt.plot(word_data['year'], word_data['freq'], \n",
    "                    marker='o', label=word, linewidth=2, color=colors[i])\n",
    "        \n",
    "        plt.title('关键词汇年度变化趋势', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('年份')\n",
    "        plt.ylabel('词频')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n🔍 分析了 {len(multi_year_words)} 个多年度出现的关键词\")\n",
    "    else:\n",
    "        print(\"❌ 没有找到多年度出现的词汇\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 TF-IDF 关键词分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not tfidf_by_year.empty:\n",
    "    # 每年Top 10 TF-IDF关键词热力图\n",
    "    years = sorted(tfidf_by_year['year'].unique())\n",
    "    \n",
    "    # 获取每年前10个关键词\n",
    "    top_words_by_year = {}\n",
    "    for year in years:\n",
    "        year_data = tfidf_by_year[tfidf_by_year['year'] == year].head(10)\n",
    "        top_words_by_year[year] = list(year_data['word'])\n",
    "    \n",
    "    # 创建词汇-年份矩阵\n",
    "    all_top_words = set()\n",
    "    for words in top_words_by_year.values():\n",
    "        all_top_words.update(words)\n",
    "    \n",
    "    # 构建热力图数据\n",
    "    matrix_data = []\n",
    "    word_labels = []\n",
    "    \n",
    "    for word in all_top_words:\n",
    "        row = []\n",
    "        for year in years:\n",
    "            if word in top_words_by_year[year]:\n",
    "                # 获取该词在该年的排名（倒序，排名越高值越大）\n",
    "                rank = top_words_by_year[year].index(word)\n",
    "                row.append(10 - rank)  # 转换为正向权重\n",
    "            else:\n",
    "                row.append(0)\n",
    "        matrix_data.append(row)\n",
    "        word_labels.append(word)\n",
    "    \n",
    "    if matrix_data:\n",
    "        plt.figure(figsize=(12, min(20, len(word_labels))))\n",
    "        \n",
    "        # 只显示至少在2年出现的词汇\n",
    "        filtered_data = []\n",
    "        filtered_labels = []\n",
    "        for i, row in enumerate(matrix_data):\n",
    "            if sum(1 for x in row if x > 0) >= 2:  # 至少在2年出现\n",
    "                filtered_data.append(row)\n",
    "                filtered_labels.append(word_labels[i])\n",
    "        \n",
    "        if filtered_data:\n",
    "            sns.heatmap(filtered_data, \n",
    "                       xticklabels=years,\n",
    "                       yticklabels=filtered_labels,\n",
    "                       cmap='YlOrRd',\n",
    "                       annot=True,\n",
    "                       fmt='d',\n",
    "                       cbar_kws={'label': '关键词重要性 (10=最重要)'})\n",
    "            \n",
    "            plt.title('年度 TF-IDF 关键词热力图', fontsize=16, fontweight='bold')\n",
    "            plt.xlabel('年份')\n",
    "            plt.ylabel('关键词')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"❌ 没有找到多年度的关键词\")\n",
    "    \n",
    "    # 显示每年的Top 5关键词\n",
    "    print(\"\\n🎯 各年度 Top 5 TF-IDF 关键词:\")\n",
    "    for year in years:\n",
    "        year_data = tfidf_by_year[tfidf_by_year['year'] == year].head(5)\n",
    "        words = ', '.join(year_data['word'].tolist())\n",
    "        print(f\"{year}: {words}\")\n",
    "else:\n",
    "    print(\"❌ 没有 TF-IDF 数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 词云展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# 显示整体词云\n",
    "overall_wordcloud_path = os.path.join(output_dir, 'wordcloud_overall.png')\n",
    "if os.path.exists(overall_wordcloud_path):\n",
    "    print(\"🎨 整体词云:\")\n",
    "    img = mpimg.imread(overall_wordcloud_path)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('整体词云', fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"❌ 整体词云文件不存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示年度词云\n",
    "if not freq_by_year.empty:\n",
    "    years = sorted(freq_by_year['year'].unique())\n",
    "    \n",
    "    # 计算子图布局\n",
    "    n_years = len(years)\n",
    "    cols = min(3, n_years)\n",
    "    rows = (n_years + cols - 1) // cols\n",
    "    \n",
    "    if rows > 0:\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "        \n",
    "        if n_years == 1:\n",
    "            axes = [axes]\n",
    "        elif rows == 1:\n",
    "            axes = axes if hasattr(axes, '__len__') else [axes]\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        found_any = False\n",
    "        \n",
    "        for i, year in enumerate(years):\n",
    "            wordcloud_path = os.path.join(output_dir, f'wordcloud_{year}.png')\n",
    "            \n",
    "            if os.path.exists(wordcloud_path):\n",
    "                img = mpimg.imread(wordcloud_path)\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f'{year} 年词云', fontweight='bold')\n",
    "                axes[i].axis('off')\n",
    "                found_any = True\n",
    "            else:\n",
    "                axes[i].text(0.5, 0.5, f'{year}\\n词云文件\\n不存在', \n",
    "                           ha='center', va='center', transform=axes[i].transAxes)\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # 隐藏多余的子图\n",
    "        for i in range(n_years, len(axes)):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        if found_any:\n",
    "            plt.suptitle('年度词云对比', fontsize=16, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "            print(\"❌ 没有找到年度词云文件\")\n",
    "else:\n",
    "    print(\"❌ 没有年度数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💭 自我鼓励与年度口号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成年度口号\n",
    "if not tfidf_by_year.empty:\n",
    "    print(\"🎯 基于关键词的年度口号:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 自我鼓励模板\n",
    "    templates = [\n",
    "        \"在{year}年，我专注于{word1}，深入探索{word2}，持续思考{word3}。\",\n",
    "        \"{year}年是{word1}之年，我在{word2}领域不断成长，对{word3}有了更深的理解。\",\n",
    "        \"回顾{year}年，{word1}是我的关键词，通过{word2}实现突破，在{word3}方面收获满满。\",\n",
    "        \"{year}年，我将{word1}作为主线，以{word2}为方法，向{word3}目标前进。\",\n",
    "        \"在{year}年的旅程中，{word1}指引方向，{word2}提供动力，{word3}带来启发。\"\n",
    "    ]\n",
    "    \n",
    "    years = sorted(tfidf_by_year['year'].unique())\n",
    "    \n",
    "    for i, year in enumerate(years):\n",
    "        year_data = tfidf_by_year[tfidf_by_year['year'] == year].head(5)\n",
    "        if len(year_data) >= 3:\n",
    "            words = year_data['word'].tolist()\n",
    "            template = templates[i % len(templates)]\n",
    "            \n",
    "            slogan = template.format(\n",
    "                year=year,\n",
    "                word1=words[0],\n",
    "                word2=words[1] if len(words) > 1 else '新领域',\n",
    "                word3=words[2] if len(words) > 2 else '人生哲理'\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n📅 {year}年:\")\n",
    "            print(f\"   {slogan}\")\n",
    "            print(f\"   关键词: {', '.join(words[:5])}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"💪 总结感言:\")\n",
    "    \n",
    "    if not freq_overall.empty:\n",
    "        total_words = len(freq_overall)\n",
    "        total_freq = freq_overall['freq'].sum()\n",
    "        year_span = len(years)\n",
    "        \n",
    "        motivation = f\"\"\"通过 {year_span} 年的写作历程，我积累了 {total_words:,} 个不同的词汇，\n",
    "总计 {total_freq:,} 次的表达。每一个词汇都承载着思考的痕迹，\n",
    "每一次表达都见证着成长的足迹。\n",
    "\n",
    "从数据中可以看出，我的表达越来越丰富，思考越来越深入。\n",
    "这不仅是文字的积累，更是智慧的沉淀。\n",
    "\n",
    "继续保持这份热情，让文字记录生活，让思考指引未来！ 🚀\"\"\"\n",
    "        \n",
    "        print(motivation)\n",
    "else:\n",
    "    print(\"❌ 没有足够的数据生成年度口号\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Zipf 定律分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 显示 Zipf 分析图\n",
    "zipf_path = os.path.join(output_dir, 'zipf_overall.png')\n",
    "if os.path.exists(zipf_path):\n",
    "    print(\"📈 Zipf 定律分析:\")\n",
    "    img = mpimg.imread(zipf_path)\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Zipf 定律分析', fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n📝 Zipf 定律解读:\")\n",
    "    print(\"\"\"Zipf 定律表明，自然语言中词频与其排名呈反比关系。\n",
    "这反映了语言使用的经济性原则：\n",
    "- 少数高频词承载主要信息传递功能\n",
    "- 大量低频词丰富表达的精确性和个性化\n",
    "- 符合 Zipf 定律的语言使用体现了自然的平衡状态\n",
    "\n",
    "从你的写作语料来看，这种分布特征表明你的文字表达既有核心主题，\n",
    "又具备丰富的细节描述，体现了成熟的写作风格。\"\"\")\n",
    "else:\n",
    "    print(\"❌ Zipf 分析图文件不存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 数据导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个汇总的数据集用于进一步分析\n",
    "if not freq_overall.empty and not freq_by_year.empty:\n",
    "    # 合并数据创建完整的分析数据集\n",
    "    analysis_summary = {\n",
    "        'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'total_unique_words': len(freq_overall),\n",
    "        'total_word_freq': freq_overall['freq'].sum(),\n",
    "        'years_covered': sorted(freq_by_year['year'].unique()) if not freq_by_year.empty else [],\n",
    "        'top_10_words': freq_overall.head(10)['word'].tolist(),\n",
    "        'diversity_index': len(freq_overall) / freq_overall['freq'].sum()\n",
    "    }\n",
    "    \n",
    "    # 保存汇总信息\n",
    "    import json\n",
    "    summary_path = os.path.join(output_dir, 'analysis_summary.json')\n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(analysis_summary, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"📊 分析汇总已保存到: {summary_path}\")\n",
    "    print(\"\\n汇总信息:\")\n",
    "    for key, value in analysis_summary.items():\n",
    "        if key != 'top_10_words':\n",
    "            print(f\"  {key}: {value}\")\n",
    "    print(f\"  top_10_words: {', '.join(analysis_summary['top_10_words'])}\")\n",
    "else:\n",
    "    print(\"❌ 数据不完整，无法生成汇总\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🎉 分析完成\n",
    "\n",
    "本笔记本完成了对个人微信公众号语料的全面分析，包括：\n",
    "\n",
    "1. **词频统计** - 了解最常用的词汇\n",
    "2. **年度趋势** - 观察写作风格的演变\n",
    "3. **关键词分析** - 识别各年度的核心主题\n",
    "4. **可视化展示** - 直观展现数据特征\n",
    "5. **自我激励** - 基于数据的正向反馈\n",
    "\n",
    "这些分析不仅展现了写作的数量特征，更重要的是体现了思维的深度和广度。\n",
    "继续保持这份对文字的热爱和对思考的坚持！ 🚀✨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}