#!/usr/bin/env python3
"""
è‡ªå®šä¹‰è¯äº‘ç”Ÿæˆå·¥å…· - Custom Word Cloud Generator
æ”¯æŒæŒ‰å¹´ä»½ã€æ—¶é—´æ®µæˆ–å®Œæ•´æ•°æ®é›†ç”Ÿæˆè¯äº‘
Supports generating word clouds by year, time period, or complete dataset
"""

import argparse
import os
import sys
from pathlib import Path
from typing import Dict, List, Optional

# Add pipeline to path
sys.path.insert(0, str(Path(__file__).parent / "pipeline"))

from corpus_io import load_corpus, read_text, split_by_year
from tokenizer import MixedLanguageTokenizer
from stats import calculate_frequencies, calculate_frequencies_by_year
from viz import create_wordcloud, setup_chinese_font


def generate_wordcloud_for_years(
    corpus_root: str,
    output_dir: str,
    years: Optional[List[str]] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    max_words: int = 200,
    font_path: Optional[str] = None,
    color_scheme: str = "nature"
) -> None:
    """
    ä¸ºæŒ‡å®šå¹´ä»½æˆ–æ—¶é—´æ®µç”Ÿæˆè¯äº‘
    Generate word clouds for specified years or time period
    
    Args:
        corpus_root: è¯­æ–™åº“æ ¹ç›®å½• / Corpus root directory
        output_dir: è¾“å‡ºç›®å½• / Output directory  
        years: å¹´ä»½åˆ—è¡¨ / List of years
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD) / Start date
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD) / End date
        max_words: æœ€å¤§è¯æ•° / Maximum words
        font_path: ä¸­æ–‡å­—ä½“è·¯å¾„ / Chinese font path
        color_scheme: é¢œè‰²æ–¹æ¡ˆ / Color scheme
    """
    
    print("ğŸš€ å¼€å§‹ç”Ÿæˆè‡ªå®šä¹‰è¯äº‘ / Starting custom word cloud generation")
    print(f"ğŸ“ è¯­æ–™åº“è·¯å¾„ / Corpus path: {corpus_root}")
    print(f"ğŸ“… å¹´ä»½ç­›é€‰ / Year filter: {years if years else 'æ‰€æœ‰å¹´ä»½ / All years'}")
    print(f"ğŸ“† æ—¥æœŸèŒƒå›´ / Date range: {start_date} ~ {end_date}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½• / Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # åŠ è½½è¯­æ–™åº“ / Load corpus
    print("ğŸ“š æ­£åœ¨åŠ è½½è¯­æ–™åº“... / Loading corpus...")
    articles = load_corpus(
        root_dir=corpus_root,
        start_date=start_date,
        end_date=end_date,
        years=years
    )
    
    if not articles:
        print("âŒ æœªæ‰¾åˆ°æ–‡ç«  / No articles found")
        return
    
    print(f"âœ… åŠ è½½äº† {len(articles)} ç¯‡æ–‡ç«  / Loaded {len(articles)} articles")
    
    # åˆå§‹åŒ–åˆ†è¯å™¨ / Initialize tokenizer
    print("ğŸ”¤ åˆå§‹åŒ–åˆ†è¯å™¨... / Initializing tokenizer...")
    tokenizer = MixedLanguageTokenizer()
    
    # æŒ‰å¹´ä»½åˆ†ç»„ / Split by year
    articles_by_year = split_by_year(articles)
    
    # å¤„ç†æ‰€æœ‰æ–‡ç« æ•°æ® / Process all article data
    all_tokens = []
    tokens_by_year = {}
    
    for year, year_articles in articles_by_year.items():
        year_tokens = []
        print(f"ğŸ“ æ­£åœ¨å¤„ç† {year} å¹´çš„ {len(year_articles)} ç¯‡æ–‡ç« ... / Processing {len(year_articles)} articles from {year}...")
        
        for article in year_articles:
            text = read_text(article)
            if text:
                tokens = tokenizer.tokenize(text)
                if tokens:
                    all_tokens.append(tokens)
                    year_tokens.append(tokens)
        
        if year_tokens:
            tokens_by_year[year] = year_tokens
            print(f"âœ… {year} å¹´: {len(year_tokens)} ç¯‡æ–‡ç« å·²åˆ†è¯ / {year}: {len(year_tokens)} articles tokenized")
    
    # è®¡ç®—è¯é¢‘ / Calculate frequencies
    print("ğŸ“Š è®¡ç®—è¯é¢‘ç»Ÿè®¡... / Calculating frequency statistics...")
    freq_overall = calculate_frequencies(all_tokens)
    freq_by_year = calculate_frequencies_by_year(tokens_by_year)
    
    # è®¾ç½®å­—ä½“ / Setup font
    font_path = setup_chinese_font(font_path)
    
    # ç”Ÿæˆæ•´ä½“è¯äº‘ / Generate overall word cloud
    if len(all_tokens) > 0:
        overall_cloud_path = os.path.join(output_dir, "cloud_complete.png")
        print("ğŸ¨ ç”Ÿæˆå®Œæ•´æ•°æ®è¯äº‘... / Generating complete dataset word cloud...")
        
        date_range = ""
        if start_date and end_date:
            date_range = f" ({start_date} ~ {end_date})"
        elif years:
            date_range = f" ({', '.join(sorted(years))})"
        
        create_wordcloud(
            frequencies=freq_overall,
            output_path=overall_cloud_path,
            title=f"å®Œæ•´æ•°æ®è¯äº‘ / Complete Word Cloud{date_range}",
            font_path=font_path,
            max_words=max_words,
            color_scheme=color_scheme
        )
        print(f"âœ… å®Œæ•´è¯äº‘å·²ä¿å­˜: {overall_cloud_path}")
    
    # ç”Ÿæˆå„å¹´ä»½è¯äº‘ / Generate yearly word clouds
    if len(freq_by_year) > 1:  # å¦‚æœæœ‰å¤šä¸ªå¹´ä»½ / If multiple years
        print("ğŸ¨ ç”Ÿæˆå¹´åº¦è¯äº‘... / Generating yearly word clouds...")
        for year, freq in freq_by_year.items():
            if freq:  # ç¡®ä¿æœ‰æ•°æ® / Ensure there's data
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŸå§‹çš„è¯äº‘æ–‡ä»¶ï¼Œé¿å…è¦†ç›–
                # Check if original word cloud exists to avoid overwriting
                original_cloud_path = os.path.join(output_dir, f"cloud_{year}.png")
                if os.path.exists(original_cloud_path):
                    print(f"âš ï¸  è·³è¿‡ {year} å¹´: åŸå§‹è¯äº‘å·²å­˜åœ¨ / Skipping {year}: original word cloud exists")
                    continue
                    
                yearly_cloud_path = os.path.join(output_dir, f"cloud_{year}.png")
                create_wordcloud(
                    frequencies=freq,
                    output_path=yearly_cloud_path,
                    title=f"{year} å¹´è¯äº‘ / {year} Word Cloud",
                    font_path=font_path,
                    max_words=max_words,
                    color_scheme=color_scheme
                )
                print(f"âœ… {year} å¹´è¯äº‘å·²ä¿å­˜: {yearly_cloud_path}")
    
    print("ğŸ‰ è¯äº‘ç”Ÿæˆå®Œæˆ! / Word cloud generation completed!")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")


def main():
    """ä¸»å‡½æ•° / Main function"""
    parser = argparse.ArgumentParser(
        description="è‡ªå®šä¹‰è¯äº‘ç”Ÿæˆå·¥å…· / Custom Word Cloud Generator",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹ / Usage Examples:

# ç”Ÿæˆæ‰€æœ‰å¹´ä»½çš„è¯äº‘ / Generate word clouds for all years:
python generate_wordclouds.py

# ç”Ÿæˆç‰¹å®šå¹´ä»½çš„è¯äº‘ / Generate word clouds for specific years:
python generate_wordclouds.py --years 2020,2021,2022,2023,2024,2025

# ç”ŸæˆæŒ‡å®šæ—¶é—´æ®µçš„è¯äº‘ / Generate word clouds for date range:
python generate_wordclouds.py --start-date 2020-01-01 --end-date 2022-12-31

# è‡ªå®šä¹‰è¾“å‡ºç›®å½•å’Œå‚æ•° / Custom output and parameters:
python generate_wordclouds.py --output custom_clouds --max-words 300 --color-scheme science
        """
    )
    
    # åŸºæœ¬å‚æ•° / Basic parameters
    parser.add_argument('--corpus', type=str, 
                       default="../Wechat-Backup/æ–‡ä¸åŠ ç‚¹çš„å¼ è¡”ç‘œ",
                       help='è¯­æ–™åº“æ ¹ç›®å½• / Corpus root directory')
    parser.add_argument('--output', type=str,
                       default="out",
                       help='è¾“å‡ºç›®å½• / Output directory')
    
    # æ—¶é—´ç­›é€‰ / Time filtering
    parser.add_argument('--years', type=str,
                       help='å¹´ä»½åˆ—è¡¨(é€—å·åˆ†éš”) / Year list (comma-separated), e.g., 2020,2021,2022')
    parser.add_argument('--start-date', type=str,
                       help='å¼€å§‹æ—¥æœŸ / Start date (YYYY-MM-DD)')
    parser.add_argument('--end-date', type=str,
                       help='ç»“æŸæ—¥æœŸ / End date (YYYY-MM-DD)')
    
    # è¯äº‘å‚æ•° / Word cloud parameters
    parser.add_argument('--max-words', type=int, default=200,
                       help='æœ€å¤§è¯æ•° / Maximum words (default: 200)')
    parser.add_argument('--font-path', type=str,
                       help='ä¸­æ–‡å­—ä½“è·¯å¾„ / Chinese font path')
    parser.add_argument('--color-scheme', choices=['nature', 'science', 'calm', 'muted', 'solar'],
                       default='nature',
                       help='é¢œè‰²æ–¹æ¡ˆ / Color scheme (default: nature)')
    
    args = parser.parse_args()
    
    # è§£æå¹´ä»½å‚æ•° / Parse years parameter
    years = None
    if args.years:
        years = [year.strip() for year in args.years.split(',')]
    
    # ç”Ÿæˆè¯äº‘ / Generate word clouds
    generate_wordcloud_for_years(
        corpus_root=args.corpus,
        output_dir=args.output,
        years=years,
        start_date=args.start_date,
        end_date=args.end_date,
        max_words=args.max_words,
        font_path=args.font_path,
        color_scheme=args.color_scheme
    )


if __name__ == "__main__":
    main()