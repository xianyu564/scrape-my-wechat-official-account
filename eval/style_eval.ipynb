{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 风格微调评测 (Style Evaluation)\n",
    "\n",
    "本notebook用于评估风格微调后的模型效果，包含三个主要评测维度：\n",
    "1. **困惑度 (PPL)** - 在保留集上比较基座模型 vs LoRA适配器\n",
    "2. **风格指示器** - 字数/句长分布、常用词频、停用词占比对比\n",
    "3. **A/B人工评测** - 盲评样本，评估\"更像作者\"的程度\n",
    "\n",
    "这些评测结果可直接用于学术论文的模型评估章节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from peft import PeftModel\n",
    "import jieba\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"环境初始化完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 模型加载与配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置路径\n",
    "BASE_MODEL = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "LORA_PATH = \"outputs/qwen25-7b-sft-lora\"\n",
    "TEST_DATA = \"data/sft_val.jsonl\"\n",
    "\n",
    "# 加载基础模型\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"正在加载基础模型...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "print(\"正在加载LoRA模型...\")\n",
    "lora_model = PeftModel.from_pretrained(base_model, LORA_PATH)\n",
    "\n",
    "print(\"模型加载完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 困惑度评测 (Perplexity Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(model, tokenizer, texts: List[str], max_length: int = 512) -> float:\n",
    "    \"\"\"\n",
    "    计算模型在给定文本上的困惑度\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            # 编码文本\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", \n",
    "                             max_length=max_length, truncation=True)\n",
    "            inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "            \n",
    "            # 计算损失\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # 累加损失和token数\n",
    "            num_tokens = inputs[\"input_ids\"].numel()\n",
    "            total_loss += loss.item() * num_tokens\n",
    "            total_tokens += num_tokens\n",
    "    \n",
    "    # 计算平均损失和困惑度\n",
    "    avg_loss = total_loss / total_tokens\n",
    "    perplexity = torch.exp(torch.tensor(avg_loss)).item()\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# 加载测试数据\n",
    "test_texts = []\n",
    "with open(TEST_DATA, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        test_texts.append(data['output'])  # 使用原文进行困惑度测试\n",
    "\n",
    "# 限制测试样本数量（避免计算时间过长）\n",
    "test_texts = test_texts[:50]\n",
    "print(f\"使用 {len(test_texts)} 个样本进行困惑度测试\")\n",
    "\n",
    "# 计算基础模型困惑度\n",
    "print(\"计算基础模型困惑度...\")\n",
    "base_ppl = calculate_perplexity(base_model, tokenizer, test_texts)\n",
    "\n",
    "# 计算LoRA模型困惑度\n",
    "print(\"计算LoRA模型困惑度...\")\n",
    "lora_ppl = calculate_perplexity(lora_model, tokenizer, test_texts)\n",
    "\n",
    "print(f\"\\n困惑度对比结果:\")\n",
    "print(f\"基础模型: {base_ppl:.2f}\")\n",
    "print(f\"LoRA模型: {lora_ppl:.2f}\")\n",
    "print(f\"改进程度: {((base_ppl - lora_ppl) / base_ppl * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 风格指示器分析 (Style Indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_style(texts: List[str]) -> Dict:\n",
    "    \"\"\"\n",
    "    分析文本的风格特征\n",
    "    \"\"\"\n",
    "    # 基础统计\n",
    "    char_counts = [len(text) for text in texts]\n",
    "    sentence_counts = [len(re.split(r'[。！？]', text)) - 1 for text in texts]\n",
    "    \n",
    "    # 分词统计\n",
    "    all_words = []\n",
    "    for text in texts:\n",
    "        words = jieba.lcut(text)\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    word_freq = Counter(all_words)\n",
    "    \n",
    "    # 停用词\n",
    "    stop_words = {'的', '了', '在', '是', '我', '有', '和', '就', '不', '人', '都', '一', '一个', '上', '也', '很', '到', '说', '要', '去', '你', '会', '着', '没有', '看', '好', '自己', '这'}\n",
    "    stop_word_count = sum(word_freq[word] for word in stop_words if word in word_freq)\n",
    "    stop_word_ratio = stop_word_count / len(all_words) if all_words else 0\n",
    "    \n",
    "    return {\n",
    "        'char_counts': char_counts,\n",
    "        'sentence_counts': sentence_counts,\n",
    "        'avg_char_per_text': np.mean(char_counts),\n",
    "        'avg_sentence_per_text': np.mean(sentence_counts),\n",
    "        'word_freq': word_freq,\n",
    "        'stop_word_ratio': stop_word_ratio,\n",
    "        'vocab_size': len(word_freq),\n",
    "        'total_words': len(all_words)\n",
    "    }\n",
    "\n",
    "# 生成样本文本进行对比\n",
    "def generate_samples(model, tokenizer, prompts: List[str], max_length: int = 200) -> List[str]:\n",
    "    \"\"\"\n",
    "    生成模型样本\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    samples = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for prompt in prompts:\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_length,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            # 移除原始prompt\n",
    "            generated = generated[len(prompt):].strip()\n",
    "            samples.append(generated)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# 准备测试prompt\n",
    "test_prompts = [\n",
    "    \"用我的口吻写一段关于日常生活的感悟：\",\n",
    "    \"请用我的风格续写：今天又是平常的一天，但是\",\n",
    "    \"用我的写作风格描述一个普通的下午：\",\n",
    "    \"以我的口吻谈谈对阅读的看法：\",\n",
    "    \"用我的风格写一段关于城市生活的观察：\"\n",
    "]\n",
    "\n",
    "print(\"生成基础模型样本...\")\n",
    "base_samples = generate_samples(base_model, tokenizer, test_prompts)\n",
    "\n",
    "print(\"生成LoRA模型样本...\")\n",
    "lora_samples = generate_samples(lora_model, tokenizer, test_prompts)\n",
    "\n",
    "# 分析原始作者文本风格\n",
    "original_texts = [data['output'] for data in [json.loads(line) for line in open(TEST_DATA, 'r', encoding='utf-8')]][:20]\n",
    "original_style = analyze_text_style(original_texts)\n",
    "\n",
    "# 分析生成文本风格\n",
    "base_style = analyze_text_style(base_samples)\n",
    "lora_style = analyze_text_style(lora_samples)\n",
    "\n",
    "print(\"\\n风格指示器对比:\")\n",
    "print(f\"平均字数 - 原文: {original_style['avg_char_per_text']:.1f}, 基础: {base_style['avg_char_per_text']:.1f}, LoRA: {lora_style['avg_char_per_text']:.1f}\")\n",
    "print(f\"停用词比例 - 原文: {original_style['stop_word_ratio']:.3f}, 基础: {base_style['stop_word_ratio']:.3f}, LoRA: {lora_style['stop_word_ratio']:.3f}\")\n",
    "print(f\"词汇多样性 - 原文: {original_style['vocab_size']}, 基础: {base_style['vocab_size']}, LoRA: {lora_style['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 可视化对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建风格对比图表\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('风格微调效果对比', fontsize=16)\n",
    "\n",
    "# 1. 字数分布对比\n",
    "axes[0, 0].hist(original_style['char_counts'], alpha=0.7, label='原文', bins=10)\n",
    "axes[0, 0].hist([len(s) for s in base_samples], alpha=0.7, label='基础模型', bins=10)\n",
    "axes[0, 0].hist([len(s) for s in lora_samples], alpha=0.7, label='LoRA模型', bins=10)\n",
    "axes[0, 0].set_title('字数分布对比')\n",
    "axes[0, 0].set_xlabel('字数')\n",
    "axes[0, 0].set_ylabel('频次')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. 高频词对比\n",
    "original_top_words = original_style['word_freq'].most_common(10)\n",
    "base_top_words = base_style['word_freq'].most_common(10)\n",
    "lora_top_words = lora_style['word_freq'].most_common(10)\n",
    "\n",
    "words = [w[0] for w in original_top_words[:5]]\n",
    "original_freqs = [original_style['word_freq'][w] / original_style['total_words'] for w in words]\n",
    "base_freqs = [base_style['word_freq'][w] / base_style['total_words'] for w in words]\n",
    "lora_freqs = [lora_style['word_freq'][w] / lora_style['total_words'] for w in words]\n",
    "\n",
    "x = np.arange(len(words))\n",
    "width = 0.25\n",
    "\n",
    "axes[0, 1].bar(x - width, original_freqs, width, label='原文')\n",
    "axes[0, 1].bar(x, base_freqs, width, label='基础模型')\n",
    "axes[0, 1].bar(x + width, lora_freqs, width, label='LoRA模型')\n",
    "axes[0, 1].set_title('高频词使用频率对比')\n",
    "axes[0, 1].set_xlabel('词汇')\n",
    "axes[0, 1].set_ylabel('使用频率')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(words)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. 困惑度对比\n",
    "models = ['基础模型', 'LoRA模型']\n",
    "ppls = [base_ppl, lora_ppl]\n",
    "colors = ['lightcoral', 'lightblue']\n",
    "axes[1, 0].bar(models, ppls, color=colors)\n",
    "axes[1, 0].set_title('困惑度对比（越低越好）')\n",
    "axes[1, 0].set_ylabel('困惑度')\n",
    "for i, v in enumerate(ppls):\n",
    "    axes[1, 0].text(i, v + 0.1, f'{v:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# 4. 综合指标雷达图\n",
    "metrics = ['字数相似度', '停用词相似度', '词汇丰富度', '困惑度']\n",
    "# 计算相似度分数（越接近1越好）\n",
    "def similarity_score(val1, val2):\n",
    "    return 1 - abs(val1 - val2) / max(val1, val2)\n",
    "\n",
    "base_scores = [\n",
    "    similarity_score(original_style['avg_char_per_text'], base_style['avg_char_per_text']),\n",
    "    similarity_score(original_style['stop_word_ratio'], base_style['stop_word_ratio']),\n",
    "    base_style['vocab_size'] / max(original_style['vocab_size'], base_style['vocab_size']),\n",
    "    1 / base_ppl * 10  # 困惑度转换为分数\n",
    "]\n",
    "\n",
    "lora_scores = [\n",
    "    similarity_score(original_style['avg_char_per_text'], lora_style['avg_char_per_text']),\n",
    "    similarity_score(original_style['stop_word_ratio'], lora_style['stop_word_ratio']),\n",
    "    lora_style['vocab_size'] / max(original_style['vocab_size'], lora_style['vocab_size']),\n",
    "    1 / lora_ppl * 10\n",
    "]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "axes[1, 1].plot(x, base_scores, 'o-', label='基础模型', linewidth=2, markersize=6)\n",
    "axes[1, 1].plot(x, lora_scores, 's-', label='LoRA模型', linewidth=2, markersize=6)\n",
    "axes[1, 1].set_title('综合风格指标对比')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(metrics, rotation=45)\n",
    "axes[1, 1].set_ylabel('相似度分数')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eval/style_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"可视化图表已保存到 eval/style_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. A/B 人工评测样本生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成A/B测试样本\n",
    "ab_test_prompts = [\n",
    "    \"用我的口吻写一段关于早晨的感受\",\n",
    "    \"以我的风格描述一次普通的购物经历\", \n",
    "    \"用我的语气谈谈对当下生活节奏的看法\",\n",
    "    \"以我的口吻写一段关于读书的心得\",\n",
    "    \"用我的风格描述一个安静的傍晚\",\n",
    "    \"以我的语气聊聊对工作的思考\",\n",
    "    \"用我的口吻写一段关于季节变化的观察\",\n",
    "    \"以我的风格描述一次偶遇\",\n",
    "    \"用我的语气谈谈对新技术的看法\",\n",
    "    \"以我的口吻写一段关于美食的感受\"\n",
    "]\n",
    "\n",
    "print(\"生成A/B测试样本...\")\n",
    "ab_base_samples = generate_samples(base_model, tokenizer, ab_test_prompts, max_length=150)\n",
    "ab_lora_samples = generate_samples(lora_model, tokenizer, ab_test_prompts, max_length=150)\n",
    "\n",
    "# 创建A/B测试数据\n",
    "ab_test_data = []\n",
    "for i, prompt in enumerate(ab_test_prompts):\n",
    "    # 随机决定A/B顺序\n",
    "    if np.random.random() > 0.5:\n",
    "        sample_a, sample_b = ab_base_samples[i], ab_lora_samples[i]\n",
    "        correct_answer = 'B'  # LoRA应该更像作者\n",
    "    else:\n",
    "        sample_a, sample_b = ab_lora_samples[i], ab_base_samples[i]\n",
    "        correct_answer = 'A'\n",
    "    \n",
    "    ab_test_data.append({\n",
    "        'id': i + 1,\n",
    "        'prompt': prompt,\n",
    "        'sample_a': sample_a,\n",
    "        'sample_b': sample_b,\n",
    "        'correct_answer': correct_answer,\n",
    "        'model_a': 'LoRA' if correct_answer == 'A' else 'Base',\n",
    "        'model_b': 'LoRA' if correct_answer == 'B' else 'Base'\n",
    "    })\n",
    "\n",
    "# 保存A/B测试数据\n",
    "with open('eval/ab_test_samples.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(ab_test_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"已生成 {len(ab_test_data)} 个A/B测试样本，保存到 eval/ab_test_samples.json\")\n",
    "\n",
    "# 显示前3个样本作为示例\n",
    "print(\"\\n=== A/B测试样本示例 ===\")\n",
    "for i in range(min(3, len(ab_test_data))):\n",
    "    sample = ab_test_data[i]\n",
    "    print(f\"\\n样本 {sample['id']}:\")\n",
    "    print(f\"提示: {sample['prompt']}\")\n",
    "    print(f\"\\n选项A ({sample['model_a']}模型):\")\n",
    "    print(sample['sample_a'][:100] + '...' if len(sample['sample_a']) > 100 else sample['sample_a'])\n",
    "    print(f\"\\n选项B ({sample['model_b']}模型):\")\n",
    "    print(sample['sample_b'][:100] + '...' if len(sample['sample_b']) > 100 else sample['sample_b'])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 评测报告生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成评测报告\n",
    "report = f\"\"\"\n",
    "# 风格微调评测报告\n",
    "\n",
    "## 模型配置\n",
    "- 基础模型: {BASE_MODEL}\n",
    "- LoRA路径: {LORA_PATH}\n",
    "- 测试样本数: {len(test_texts)}\n",
    "\n",
    "## 1. 困惑度评测结果\n",
    "\n",
    "| 模型 | 困惑度 | 改进程度 |\n",
    "|------|--------|----------|\n",
    "| 基础模型 | {base_ppl:.2f} | - |\n",
    "| LoRA模型 | {lora_ppl:.2f} | {((base_ppl - lora_ppl) / base_ppl * 100):.1f}% |\n",
    "\n",
    "## 2. 风格指示器对比\n",
    "\n",
    "| 指标 | 原文 | 基础模型 | LoRA模型 |\n",
    "|------|------|----------|----------|\n",
    "| 平均字数 | {original_style['avg_char_per_text']:.1f} | {base_style['avg_char_per_text']:.1f} | {lora_style['avg_char_per_text']:.1f} |\n",
    "| 平均句数 | {original_style['avg_sentence_per_text']:.1f} | {base_style['avg_sentence_per_text']:.1f} | {lora_style['avg_sentence_per_text']:.1f} |\n",
    "| 停用词比例 | {original_style['stop_word_ratio']:.3f} | {base_style['stop_word_ratio']:.3f} | {lora_style['stop_word_ratio']:.3f} |\n",
    "| 词汇多样性 | {original_style['vocab_size']} | {base_style['vocab_size']} | {lora_style['vocab_size']} |\n",
    "\n",
    "## 3. A/B人工评测\n",
    "\n",
    "已生成 {len(ab_test_data)} 个A/B测试样本，可供人工评测使用。\n",
    "评测文件: `eval/ab_test_samples.json`\n",
    "\n",
    "### 评测说明:\n",
    "1. 对每个样本，比较选项A和选项B哪个更像原作者的写作风格\n",
    "2. 记录选择结果和置信度\n",
    "3. 统计LoRA模型的胜率\n",
    "\n",
    "## 4. 结论\n",
    "\n",
    "- **困惑度改善**: LoRA微调{'显著' if (base_ppl - lora_ppl) / base_ppl > 0.1 else '适度'}降低了模型困惑度\n",
    "- **风格一致性**: LoRA模型在{'字数分布、句长特征' if abs(lora_style['avg_char_per_text'] - original_style['avg_char_per_text']) < abs(base_style['avg_char_per_text'] - original_style['avg_char_per_text']) else '词汇使用'}等方面更接近原作者风格\n",
    "- **评测可用性**: 生成的A/B测试样本可直接用于论文的人工评测章节\n",
    "\n",
    "---\n",
    "报告生成时间: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# 保存报告\n",
    "with open('eval/style_evaluation_report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"评测报告已保存到 eval/style_evaluation_report.md\")\n",
    "print(\"\\n=== 评测完成 ===\")\n",
    "print(f\"主要结果:\")\n",
    "print(f\"- 困惑度改进: {((base_ppl - lora_ppl) / base_ppl * 100):.1f}%\")\n",
    "print(f\"- A/B测试样本: {len(ab_test_data)} 个\")\n",
    "print(f\"- 可视化图表: eval/style_comparison.png\")\n",
    "print(f\"- 详细报告: eval/style_evaluation_report.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}